{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      val   val.1  val.2  val.3  val.4  val.5        mu\n",
      "0   69.05   43.50 -23.12   1.00    1.1   -3.7  0.122147\n",
      "1   60.75   34.33 -15.00   1.67    1.1   -5.8  0.050202\n",
      "2   55.60   44.00  -8.05   2.85    1.1   -8.5  0.058697\n",
      "3   63.50   53.75  -1.43   3.95    1.2   -9.1  0.182528\n",
      "4   62.33   82.57   6.03   6.33    1.5   76.4  0.234987\n",
      "..    ...     ...    ...    ...    ...    ...       ...\n",
      "79  61.93  109.15  16.28  13.98    1.8   86.4  0.148817\n",
      "80  74.20  259.08   9.73  10.52    1.5   61.0  0.175548\n",
      "81  74.93   77.93   2.95   6.53    1.2    0.7  0.172814\n",
      "82  77.00   57.15  -3.83   4.57    1.1  -18.1  0.169309\n",
      "83  73.93   62.28 -11.73   2.62    1.1   -7.5  0.163561\n",
      "\n",
      "[84 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "_dir = os.path.abspath('')\n",
    "data_path = os.path.join(_dir, \"../data/cleaned_data.csv\")\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      val   val.1  val.2  val.3  val.4  val.5        mu\n",
      "0   69.05   43.50 -23.12   1.00    1.1   -3.7  0.122147\n",
      "1   60.75   34.33 -15.00   1.67    1.1   -5.8  0.050202\n",
      "2   55.60   44.00  -8.05   2.85    1.1   -8.5  0.058697\n",
      "3   63.50   53.75  -1.43   3.95    1.2   -9.1  0.182528\n",
      "4   62.33   82.57   6.03   6.33    1.5   76.4  0.234987\n",
      "5   64.72  127.23  12.05  10.05    2.1  116.3  0.188156\n",
      "6   62.20   67.75  15.95  13.98    2.2  117.1  0.191477\n",
      "7   68.15   75.32  13.53  12.73    2.2   86.2  0.138820\n",
      "8   62.55  103.60  11.23  10.55    1.8   57.9  0.178267\n",
      "9   68.75   56.33   3.75   6.93    1.4  -13.1  0.200559\n",
      "10  79.28   66.75  -3.93   4.20    1.1  -13.0  0.192960\n",
      "11  59.08   62.15 -16.88   1.77    1.1   -6.0  0.161768\n",
      "12  60.00   29.35 -20.00   1.20    1.1   -6.8  0.121903\n",
      "13  59.08   36.08 -14.62   1.70    1.1   -4.9  0.063480\n",
      "14  63.40   47.03 -10.12   2.35    1.1   -8.9  0.054093\n",
      "15  65.12   64.43   1.57   4.65    1.1   -7.6  0.156610\n",
      "16  61.88   37.67   7.38   7.28    1.4   64.0  0.192563\n",
      "17  61.80  101.43  16.18  12.88    1.7   88.6  0.158119\n",
      "18  53.25   62.08  17.58  13.95    1.9   96.5  0.100601\n",
      "19  59.55  158.17  15.98  13.45    1.8   87.5  0.085466\n",
      "20  65.60  147.03  11.62  10.88    1.5   56.4  0.126442\n",
      "21  76.90  146.82   4.85   8.03    1.2  -23.1  0.152623\n",
      "22  79.45   90.78  -4.35   4.40    1.1  -17.1  0.155313\n",
      "23  68.28   61.40 -14.30   2.03    1.1   -9.1  0.127612\n",
      "24  67.35   83.08 -12.85   2.62    1.1   -5.2  0.070598\n",
      "25  65.53   59.33 -16.50   1.85    1.1   -3.6  0.044802\n",
      "26  70.25   37.17  -6.53   3.27    1.1   -8.9  0.048039\n",
      "27  60.43   42.98   1.93   4.75    1.1    9.0  0.158672\n",
      "28  61.85   67.20   9.43   8.80    1.6   84.1  0.163605\n",
      "29  62.75   83.47  14.90  12.05    2.1  120.9  0.122011\n",
      "30  60.68  116.32  17.05  14.50    2.2   98.7  0.125101\n",
      "31  63.18   79.15  13.88  12.25    2.1   74.1  0.136301\n",
      "32  66.33  207.32   9.38   9.70    1.8   53.1  0.145860\n",
      "33  77.43  154.52   2.55   6.62    1.4   34.4  0.162175\n",
      "34  79.43   56.85  -2.05   5.05    1.2  -12.7  0.162049\n",
      "35  70.33   57.25  -9.40   3.35    1.1   -5.6  0.139808\n",
      "      val   val.1  val.2  val.3  val.4  val.5        mu\n",
      "36  67.83   77.20 -15.95   2.40    1.1   -5.7  0.083463\n",
      "37  61.93   42.02 -20.20   1.25    1.1   -4.9  0.025093\n",
      "38  57.55   39.33  -9.65   2.80    1.1   -7.2  0.032611\n",
      "39  62.75   46.38  -0.47   4.60    1.2   13.1  0.101946\n",
      "40  51.23   27.05   8.20   6.85    1.5   75.6  0.154004\n",
      "41  60.18   80.90  14.45  11.55    1.9   94.7  0.121582\n",
      "42  58.95   81.53  15.65  13.83    2.2   88.3  0.117175\n",
      "43  62.70  194.73  14.40  12.77    2.1   68.3  0.110532\n",
      "44  63.80  131.45  10.55  10.30    1.8   47.4  0.138874\n",
      "45  73.30  112.38   5.55   7.57    1.4  -26.8  0.151146\n",
      "46  78.47   78.35  -5.62   3.85    1.1  -14.6  0.150427\n",
      "47  65.28   68.03 -15.20   2.03    1.1   -5.2  0.119916\n",
      "48  67.05   52.40 -14.83   2.60    1.1   -3.2  0.129079\n",
      "49  57.88   40.40 -16.75   1.93    1.1   -5.2  0.084035\n",
      "50  55.55   83.53 -12.23   2.28    1.1   -9.0  0.040545\n",
      "51  62.00   86.78   1.48   4.90    1.2   10.5  0.120544\n",
      "52  59.95   62.30   6.25   6.65    1.5   74.3  0.173524\n",
      "53  70.90  149.58  13.95  12.50    2.0  116.5  0.161229\n",
      "54  68.62  121.18  16.43  14.65    2.2   91.6  0.165923\n",
      "55  64.95   40.88  14.53  13.68    2.2   76.9  0.151453\n",
      "56  64.73  121.23  10.02  10.43    1.8   50.0  0.139671\n",
      "57  74.03   92.23   3.10   6.65    1.4  -21.8  0.171450\n",
      "58  80.62   67.00  -3.98   4.73    1.2  -16.1  0.171009\n",
      "59  61.95   77.68 -16.10   2.12    1.1   -6.7  0.137361\n",
      "      val   val.1  val.2  val.3  val.4  val.5        mu\n",
      "60  64.82   38.70 -21.65   1.30    1.1   -6.0  0.103205\n",
      "61  62.48   51.60 -15.90   2.17    1.1   -7.1  0.036456\n",
      "62  54.40   26.10  -9.62   2.70    1.1   -9.1  0.046162\n",
      "63  63.30   48.10   0.30   4.65    1.3  -18.0  0.153092\n",
      "64  58.43   75.85   6.08   6.43    1.9  118.2  0.190333\n",
      "65  64.28   45.17  13.52  11.60    2.2  126.0  0.132500\n",
      "66  68.88  143.18  14.70  14.10    2.2  108.7  0.099326\n",
      "67  66.68  100.18  15.05  13.65    2.2   81.3  0.126382\n",
      "68  64.32  104.08  10.30   9.93    1.9   48.6  0.130342\n",
      "69  78.33   85.33   1.45   6.23    1.4  -26.5  0.152197\n",
      "70  77.85   59.33  -1.00   5.35    1.2  -14.8  0.161293\n",
      "71  71.12   87.45 -13.03   2.60    1.1   -7.5  0.130388\n",
      "72  70.65   38.85 -14.38   2.45    1.1   -4.4  0.098512\n",
      "73  75.55   32.92 -12.30   2.53    1.1   -4.9  0.086583\n",
      "74  54.10   31.98  -4.60   3.35    1.1   -8.4  0.088141\n",
      "75  60.63   25.83   3.20   5.38    1.1    8.3  0.179853\n",
      "76  55.48   65.45  10.07   8.20    1.3   57.1  0.158464\n",
      "77  61.92   90.53  13.23  10.88    1.6   84.5  0.081447\n",
      "78  61.83   99.95  17.75  15.27    1.9   96.0  0.119239\n",
      "79  61.93  109.15  16.28  13.98    1.8   86.4  0.148817\n",
      "80  74.20  259.08   9.73  10.52    1.5   61.0  0.175548\n",
      "81  74.93   77.93   2.95   6.53    1.2    0.7  0.172814\n",
      "82  77.00   57.15  -3.83   4.57    1.1  -18.1  0.169309\n",
      "83  73.93   62.28 -11.73   2.62    1.1   -7.5  0.163561\n"
     ]
    }
   ],
   "source": [
    "# preprocess the data\n",
    "# split it into train, validation, test sets\n",
    "train_df = df.iloc[:36]\n",
    "print(train_df)\n",
    "valid_df = df.iloc[36:60]\n",
    "print(valid_df)\n",
    "test_df = df.iloc[60:]\n",
    "print(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 6)\n"
     ]
    }
   ],
   "source": [
    "# setup train data\n",
    "train_x, train_y = train_df.iloc[:, :-1].to_numpy(), train_df.iloc[:, [-1]].to_numpy() # raw numpy\n",
    "\n",
    "# setup validation data\n",
    "valid_x, valid_y = valid_df.iloc[:, :-1].to_numpy(), valid_df.iloc[:, [-1]].to_numpy()\n",
    "\n",
    "# setup test data\n",
    "test_x, test_y = test_df.iloc[:, :-1].to_numpy(), test_df.iloc[:, [-1]].to_numpy()\n",
    "\n",
    "#print(train_x)\n",
    "#print(train_y)\n",
    "\n",
    "# convert to torch datasets\n",
    "# train data\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "# validation data\n",
    "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
    "# test data\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "batch_size = 6 # hyperparam for batch size\n",
    "\n",
    "# setup DataLoaders\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=True, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=True, batch_size=batch_size)\n",
    "\n",
    "\n",
    "print(train_x.shape)\n",
    "\n",
    "# setup pytorch to use cuda (gpu training) if possible\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup architecture of LSTM model\n",
    "class SoilNet(nn.Module):\n",
    "    def __init__(self, feature_size, output_size, hidden_dim, n_layers):\n",
    "        super(SoilNet, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        self.lstm = nn.LSTM(feature_size, hidden_dim, batch_first=True) # LSTM layer\n",
    "        #self.dropout = nn.Dropout(drop_prob) # dropout layer, probably not necessary with only 6 features...\n",
    "        self.predict = nn.Linear(hidden_dim, output_size) # output layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, _ = self.lstm(x.view(len(x), 1, -1))\n",
    "        pred = self.predict(lstm_out.view(len(x), -1))\n",
    "        return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "SoilNet(\n",
      "  (lstm): LSTM(6, 128, batch_first=True)\n",
      "  (predict): Linear(in_features=128, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define arguments and instantiate model\n",
    "feature_size = 6 # 6 features\n",
    "output_size = 1 # just output a number\n",
    "hidden_dim = 128 # size of hidden state and cell state at each time step\n",
    "n_layers = 2\n",
    "\n",
    "print(device)\n",
    "\n",
    "model = SoilNet(feature_size, output_size, hidden_dim, n_layers)\n",
    "model = model.double()\n",
    "model.to(device)\n",
    "\n",
    "# hyperparams\n",
    "lr=0.005\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/2... Step: 1... Loss: 0.003653... Validation Loss: 0.003925\n",
      "Epoch: 1/2... Step: 2... Loss: 0.003605... Validation Loss: 0.003228\n",
      "Epoch: 1/2... Step: 3... Loss: 0.005022... Validation Loss: 0.002572\n",
      "Epoch: 1/2... Step: 4... Loss: 0.006836... Validation Loss: 0.002319\n",
      "Epoch: 1/2... Step: 5... Loss: 0.001898... Validation Loss: 0.002865\n",
      "Epoch: 1/2... Step: 6... Loss: 0.002595... Validation Loss: 0.004136\n",
      "Epoch: 2/2... Step: 7... Loss: 0.002395... Validation Loss: 0.004514\n",
      "Epoch: 2/2... Step: 8... Loss: 0.000795... Validation Loss: 0.004128\n",
      "Epoch: 2/2... Step: 9... Loss: 0.004753... Validation Loss: 0.003280\n",
      "Epoch: 2/2... Step: 10... Loss: 0.003354... Validation Loss: 0.002320\n",
      "Epoch: 2/2... Step: 11... Loss: 0.003814... Validation Loss: 0.002187\n",
      "Epoch: 2/2... Step: 12... Loss: 0.004402... Validation Loss: 0.002233\n"
     ]
    }
   ],
   "source": [
    "# now start the training\n",
    "epochs = 2\n",
    "counter = 0\n",
    "valid_loss_min = np.Inf\n",
    "\n",
    "model.train()\n",
    "for i in range(epochs):    \n",
    "    for inputs, labels in train_loader:\n",
    "        counter += 1\n",
    "        optimizer.zero_grad()\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        #print(inputs)\n",
    "        y_pred = model(inputs.cuda())\n",
    "        \n",
    "        loss = criterion(y_pred, labels.cuda())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # do validation here\n",
    "        val_losses = []\n",
    "        model.eval()\n",
    "        for inp, lab in valid_loader:\n",
    "            inp, lab = inp.to(device), lab.to(device)\n",
    "            val_out = model(inp.cuda())\n",
    "            val_loss = criterion(val_out, lab.cuda())\n",
    "            val_losses.append(val_loss.item())\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        # print stuff here\n",
    "        print(\"Epoch: {}/{}...\".format(i+1, epochs),\n",
    "                  \"Step: {}...\".format(counter),\n",
    "                  \"Loss: {:.6f}...\".format(loss.item()),\n",
    "                  \"Validation Loss: {:.6f}\".format(np.mean(val_losses)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  [0.0011746644763321126, 0.0024528105013722004, 0.0010338094452213488, 0.0015597434763214948]\n",
      "[0.10146143505201931, 0.07371485993516688, 0.11916405107177873, 0.11979740720896144, 0.04267764307009221, 0.11928014513908854, 0.07347810599997297, 0.11519151081771702, 0.14518082763932497, 0.08736716412244107, 0.14081182071463705, 0.17988216867677226, 0.08721132081601539, 0.13364888113389806, 0.20163440014586095, 0.11486611667701606, 0.14787361112987893, 0.1291463218034714, 0.13569190645350993, 0.04948930149314386, 0.12899652856152263, 0.06008494139953598, 0.12178414341073683, 0.2339041964698658]\n",
      "[0.0993261088709677, 0.103205309139785, 0.12638180901143198, 0.179852501737318, 0.0461615750169722, 0.169309059233449, 0.0881411290322581, 0.190332661290323, 0.15846438172042998, 0.16356132392473097, 0.161292534722222, 0.130342251563586, 0.0364564648729447, 0.132499652294854, 0.15219724462365603, 0.148817126269956, 0.153092361111111, 0.130387936827957, 0.17281412037037, 0.0865833333333333, 0.11923870532703999, 0.0985124327956989, 0.081446590118302, 0.175548141086749]\n"
     ]
    }
   ],
   "source": [
    "# now check accuracy for test set...\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "model.eval()\n",
    "for inputs, labels in test_loader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    y_pred = model(inputs.cuda())\n",
    "    \n",
    "    test_loss = criterion(y_pred, labels.cuda())\n",
    "    test_losses.append(test_loss.item())\n",
    "    pred_cpu = y_pred.cpu()\n",
    "    pred_cpu = pred_cpu.detach().numpy()[:, 0]\n",
    "    pred_cpu = pred_cpu.tolist()\n",
    "    \n",
    "    lab_cpu = labels.cpu()\n",
    "    lab_cpu = lab_cpu.numpy()[:, 0]\n",
    "    lab_cpu = lab_cpu.tolist()\n",
    "    \n",
    "    predictions.extend(pred_cpu)\n",
    "    actuals.extend(lab_cpu)\n",
    "    \n",
    "\n",
    "print(\"Test loss: \", test_losses)\n",
    "print(\"Predictions:\")\n",
    "print(predictions)\n",
    "print()\n",
    "print(\"Actual values:\")\n",
    "print(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
