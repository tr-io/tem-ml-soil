{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "import tensorflow as tf\n",
    "\n",
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      precip  solar   air  vapor     label\n",
      "0        0.0  359.6   6.2    5.0  0.000000\n",
      "1        0.0  334.0   6.0    4.8  0.000000\n",
      "2        0.0  347.7   6.2    5.0  0.000000\n",
      "3        0.0  335.8  14.0    7.7  0.000000\n",
      "4        0.4  319.7  15.6   10.0  0.000000\n",
      "...      ...    ...   ...    ...       ...\n",
      "2766     0.1   51.4 -16.2    1.4  0.142646\n",
      "2767     0.0   59.1 -17.2    1.3  0.140948\n",
      "2768     0.2   24.4 -13.7    1.9  0.139318\n",
      "2769     0.1   33.7  -3.1    3.8  0.138547\n",
      "2770     3.1    4.1   1.3    6.2  0.138313\n",
      "\n",
      "[2771 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# load the data\n",
    "_dir = os.path.abspath('')\n",
    "data_path = os.path.join(_dir, \"../data/daily_cleaned.csv\")\n",
    "df = pd.read_csv(data_path)\n",
    "df = df.drop(df.columns[0], axis=1)\n",
    "new_columns = df.columns.values\n",
    "new_columns[-1] = 'label'\n",
    "df.columns = new_columns\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create series_to_supervised() function\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "\n",
    "def series_to_supervised(data, n_in=1, n_out=1, dropnan=True):\n",
    "    \"\"\"\n",
    "    Frame a time series as a supervised learning dataset.\n",
    "    Arguments:\n",
    "        data: Sequence of observations as a list or NumPy array.\n",
    "        n_in: Number of lag observations as input (X).\n",
    "        n_out: Number of observations as output (y).\n",
    "        dropnan: Boolean whether or not to drop rows with NaN values.\n",
    "    Returns:\n",
    "        Pandas DataFrame of series framed for supervised learning.\n",
    "    \"\"\"\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence: (t-n, ..., t-1)\n",
    "    for i in range(n_in, 0, -1):\n",
    "        cols.append(df.shift(i))\n",
    "        names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # forecast sequence (t, t+1, ..., t+n)\n",
    "    for i in range(0, n_out):\n",
    "        cols.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            names += [('var%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            names += [('var%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # concatenate together\n",
    "    agg = pd.concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      var1(t-1)  var2(t-1)  var3(t-1)  var4(t-1)  var5(t-1)   var5(t)\n",
      "1           0.0      359.6        6.2        5.0   0.000000  0.000000\n",
      "2           0.0      334.0        6.0        4.8   0.000000  0.000000\n",
      "3           0.0      347.7        6.2        5.0   0.000000  0.000000\n",
      "4           0.0      335.8       14.0        7.7   0.000000  0.000000\n",
      "5           0.4      319.7       15.6       10.0   0.000000  0.000000\n",
      "...         ...        ...        ...        ...        ...       ...\n",
      "2766        0.2       49.5      -17.6        1.3   0.144958  0.142646\n",
      "2767        0.1       51.4      -16.2        1.4   0.142646  0.140948\n",
      "2768        0.0       59.1      -17.2        1.3   0.140948  0.139318\n",
      "2769        0.2       24.4      -13.7        1.9   0.139318  0.138547\n",
      "2770        0.1       33.7       -3.1        3.8   0.138547  0.138313\n",
      "\n",
      "[2770 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "# testing series to supervised\n",
    "values = df.values\n",
    "data = series_to_supervised(values)\n",
    "# drop the columns we don't want to predict (predicting for current time step), so all vars at time t except var5(t)\n",
    "data.drop(data.columns[[5, 6, 7, 8]], axis=1, inplace=True)\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset into train, validation, test sets\n",
    "values = data.values\n",
    "train_df = values[:1386, :]\n",
    "valid_df = values[1386:2079, :]\n",
    "test_df = values[2079:, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1386, 1, 5) (1386,) (693, 1, 5) (693,) (691, 1, 5) (691,)\n"
     ]
    }
   ],
   "source": [
    "# setup train data\n",
    "train_x, train_y = train_df[:, :-1], train_df[:, -1] # raw numpy\n",
    "\n",
    "# setup validation data\n",
    "valid_x, valid_y = valid_df[:, :-1], valid_df[:, -1]\n",
    "\n",
    "# setup test data\n",
    "test_x, test_y = test_df[:, :-1], test_df[:, -1]\n",
    "\n",
    "batch_size = 30\n",
    "\n",
    "# reshape inputs (x's) to be 3D [seq_len, batch, input_size]\n",
    "# using batches of 30, sequence length should always be 1\n",
    "# should be (30, 1, m)\n",
    "train_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\n",
    "valid_x = valid_x.reshape((valid_x.shape[0], 1, valid_x.shape[1]))\n",
    "test_x = test_x.reshape((test_x.shape[0], 1, test_x.shape[1]))\n",
    "\n",
    "print(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape, test_x.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Physical devices cannot be modified after being initialized",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-60fbb86614b6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# let memory grow...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mphysical_devices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlist_physical_devices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'GPU'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphysical_devices\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# create keras model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\config.py\u001b[0m in \u001b[0;36mset_memory_growth\u001b[1;34m(device, enable)\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[0mRuntimeError\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mRuntime\u001b[0m \u001b[1;32mis\u001b[0m \u001b[0malready\u001b[0m \u001b[0minitialized\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    593\u001b[0m   \"\"\"\n\u001b[1;32m--> 594\u001b[1;33m   \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_memory_growth\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    595\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    596\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\eager\\context.py\u001b[0m in \u001b[0;36mset_memory_growth\u001b[1;34m(self, dev, enable)\u001b[0m\n\u001b[0;32m   1447\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1448\u001b[0m       raise RuntimeError(\n\u001b[1;32m-> 1449\u001b[1;33m           \"Physical devices cannot be modified after being initialized\")\n\u001b[0m\u001b[0;32m   1450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1451\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_memory_growth_map\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdev\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0menable\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Physical devices cannot be modified after being initialized"
     ]
    }
   ],
   "source": [
    "# begin keras training...\n",
    "# let memory grow...\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], enable=True)\n",
    "# create keras model\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mae', optimizer='adam')\n",
    "# fit the model\n",
    "history = model.fit(train_x, train_y, epochs=50, batch_size=30, validation_data=(valid_x, valid_y), verbose=2, shuffle=False)\n",
    "# plot the history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='validation')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup pytorch to use cuda (gpu training) if possible\n",
    "# pytorch stuff\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "\n",
    "# convert to torch tensors\n",
    "train_x = torch.from_numpy(train_x).float().to(device)\n",
    "train_y = torch.from_numpy(train_y).float().to(device)\n",
    "\n",
    "valid_x = torch.from_numpy(valid_x).float().to(device)\n",
    "valid_y = torch.from_numpy(valid_y).float().to(device)\n",
    "\n",
    "test_x = torch.from_numpy(test_x).float().to(device)\n",
    "test_y = torch.from_numpy(test_y).float().to(device)\n",
    "\n",
    "print(train_x.shape, train_y.shape, valid_x.shape, valid_y.shape, test_x.shape, test_y.shape)\n",
    "\"\"\"\n",
    "# convert to torch datasets\n",
    "# train data\n",
    "train_data = TensorDataset(torch.from_numpy(train_x), torch.from_numpy(train_y))\n",
    "# validation data\n",
    "valid_data = TensorDataset(torch.from_numpy(valid_x), torch.from_numpy(valid_y))\n",
    "# test data\n",
    "test_data = TensorDataset(torch.from_numpy(test_x), torch.from_numpy(test_y))\n",
    "\n",
    "# setup DataLoaders\n",
    "train_loader = DataLoader(train_data, shuffle=False, batch_size=batch_size)\n",
    "valid_loader = DataLoader(valid_data, shuffle=False, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup architecture of LSTM model\n",
    "class SoilNet(nn.Module):\n",
    "    def __init__(self, feature_size, output_size, hidden_size, seq_len, n_layers=2):\n",
    "        super(SoilNet, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.seq_len = seq_len\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.lstm = nn.LSTM(feature_size, hidden_size, n_layers) # LSTM layer\n",
    "        self.predict = nn.Linear(hidden_size, output_size) # output layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        lstm_out, self.hidden = self.lstm(x.view(len(x), self.seq_len, -1), self.hidden)\n",
    "        last_time_step = lstm_out.view(self.seq_len, len(x), self.hidden_size)[-1]\n",
    "        y_pred = self.predict(last_time_step)\n",
    "        return y_pred\n",
    "    \n",
    "    def init_hidden(self):\n",
    "        self.hidden = (torch.zeros(self.n_layers, self.seq_len, self.hidden_size).float().to(device), torch.zeros(self.n_layers, self.seq_len, self.hidden_size).float().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "SoilNet(\n",
      "  (lstm): LSTM(5, 50, num_layers=2)\n",
      "  (predict): Linear(in_features=50, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# define arguments and instantiate model\n",
    "feature_size = 5 # 5 features\n",
    "output_size = 1 # just output a number\n",
    "hidden_dim = 50 # size of hidden state and cell state at each time step\n",
    "seq_len = 1\n",
    "n_layers = 2\n",
    "\n",
    "print(device)\n",
    "\n",
    "model = SoilNet(feature_size, output_size, hidden_dim, seq_len, n_layers)\n",
    "model = model.float()\n",
    "model.to(device)\n",
    "\n",
    "# hyperparams\n",
    "lr=0.005\n",
    "criterion = nn.MSELoss(reduction='sum')\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Leo\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\loss.py:446: UserWarning: Using a target size (torch.Size([1386])) that is different to the input size (torch.Size([1386, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    }
   ],
   "source": [
    "# now start the training\n",
    "epochs = 10\n",
    "train_hist = np.zeros(epochs)\n",
    "\n",
    "model.train() # set to training mode\n",
    "for i in range(epochs):\n",
    "    model.init_hidden()\n",
    "    optimizer.zero_grad()\n",
    "    y_pred = model(train_x)\n",
    "    loss = criterion(y_pred.float(), train_y)\n",
    "    \n",
    "    train_hist[i] = loss.item()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    val_losses = []\n",
    "    model.eval()\n",
    "    \n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss:  [0.005716411584264437, 0.004094231013504453, 0.004811074350466154, 0.002719409148891785]\n",
      "Mean test loss:  0.004335281524281708\n",
      "Predictions:\n",
      "[0.12422963102828122, 0.07597662783819323, 0.06288123502311305, 0.09041999476568373, 0.15030129989379576, 0.05322136544208819, 0.08266845679021903, 0.01890145984519781, 0.03230656745696325, 0.06316190664256519, 0.16552776916354603, 0.13374768384265248, 0.1483001103496152, 0.06649637069491482, 0.10380046530567676, 0.08897690126704091, 0.10861928266783023, 0.02876654099225038, 0.061777439367065964, 0.17629317428925878, 0.030901829904294804, 0.13954610532173262, 0.0732079012001161, 0.058419058777066595]\n",
      "\n",
      "Actual values:\n",
      "[0.130342251563586, 0.175548141086749, 0.0985124327956989, 0.179852501737318, 0.190332661290323, 0.169309059233449, 0.16356132392473097, 0.0461615750169722, 0.15219724462365603, 0.103205309139785, 0.132499652294854, 0.11923870532703999, 0.081446590118302, 0.0993261088709677, 0.148817126269956, 0.130387936827957, 0.17281412037037, 0.153092361111111, 0.0865833333333333, 0.15846438172042998, 0.0881411290322581, 0.12638180901143198, 0.0364564648729447, 0.161292534722222]\n"
     ]
    }
   ],
   "source": [
    "# now check accuracy for test set...\n",
    "test_losses = []\n",
    "num_correct = 0\n",
    "\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "model.eval()\n",
    "for inputs, labels in test_loader:\n",
    "    inputs, labels = inputs.to(device), labels.to(device)\n",
    "    y_pred = model(inputs.cuda())\n",
    "    \n",
    "    test_loss = criterion(y_pred, labels.cuda())\n",
    "    test_losses.append(test_loss.item())\n",
    "    pred_cpu = y_pred.cpu()\n",
    "    pred_cpu = pred_cpu.detach().numpy()[:, 0]\n",
    "    pred_cpu = pred_cpu.tolist()\n",
    "    \n",
    "    lab_cpu = labels.cpu()\n",
    "    lab_cpu = lab_cpu.numpy()[:, 0]\n",
    "    lab_cpu = lab_cpu.tolist()\n",
    "    \n",
    "    predictions.extend(pred_cpu)\n",
    "    actuals.extend(lab_cpu)\n",
    "    \n",
    "\n",
    "print(\"Test loss: \", test_losses)\n",
    "print(\"Mean test loss: \", np.mean(test_losses))\n",
    "print(\"Predictions:\")\n",
    "print(predictions)\n",
    "print()\n",
    "print(\"Actual values:\")\n",
    "print(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
